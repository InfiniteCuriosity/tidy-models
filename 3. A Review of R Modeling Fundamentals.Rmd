---
title: "3. A Review of R Modeling Fundamentals"
author: "Russ Conte"
date: '2022-05-25'
output: html_document
---

Start by loading the required packages in two lines of code:

```{r Load all required packages in two lines of code}

Packages <- c("tidyverse", "caret", "broom")
lapply(Packages, library, character = TRUE)

```

Start with code for multi-core processing

```{r multi-core processing}

library(doParallel)
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

```

Before describing how to use tidymodels for applying tidy data principles to building models with our, let's review how models are created, trained, and used in the core our language left parenthesis often called "base R"). This Chapter is a brief illustration of core language conventions that are important to be aware of even if you never use base R for models at all. This chapter is not exhaustive, but it provides readers (especially those new to our) the most basic commonly used motifs.

## 3.1 An Example

To demonstrate some fundamentals from modeling and base are, let's use experimental data from McDonald (2009), by way of Mangiafico (2015), on the relationship between the ambient temperature and the rate of cricket trips per minute. Data were collected on to species: *oh! Honest and oh Nevius*O. exclamationis* and *O. niveus.* The data are contained in a data frame called `crickets` with a total of 31 data points. The data is shown in figure 3.1 using the following **ggplot2** code:

```{r ggplot of cricket data code}

data(crickets, package = "modeldata")
names(crickets)

```

Plot the temperature on the x-axis and the chirp rate on the y-axis. The plot elements will be colored differently for each of the two species:

```{r Plot of the chirps of two cricket species using ggplot2}

ggplot(crickets,
       aes(x = temp, y = rate, color = species, pch = species, lty = species)) +
  geom_point(size = 2) +
  geom_smooth(method = lm, se = FALSE, alpha = 0.5) +
  scale_color_brewer(palette = "Paired") +
  labs(x = "Temperature (C)", y = "Chirp Rate (per minute)") +
  ggtitle("Figure 3.1, Relationship between chirp rate and temperature for two different species of crickets")

```

The model formula `rate ~ temp + species` Creates a model with different y-intercepts for each species: the slope of the regression lines could be different for each species as well. To accommodate the structure, and interaction term can be added to the model. This can be specified in a few different ways, the most basic uses the colon:

```{r Looking at interaction terms in base R}

rate ~ temp + species + temp:species

```

A shortcut can be used to expand all interactions containing interactions with two variables:

```{r All interactions}

rate ~ (temp + species) ^ 2

```

Another shortcut to expand factors to include all possible interactions (equivalent for this example):

```{r Another shortcut}

rate ~ temp * species

```

In addition to the convenience of automatically creating indicator variables, the formula offers a few other niceties:

* *In-line* Functions can be used in the formula for example to use the natural log of the temperature, we can create the formula `rate ~ log(temp`. Since the formula is symbolic by default, math can also be applied to the predictors using the identity function, `I()`. To use Fahrenheit units, the formula could be `rate ~ I( (temp * (9/5) + 32`to convert from Celsius.

* R has many functions that are useful inside of formulas. For example, `poly(x, 3` creates linear, quadratic, and cubic terms for `x` to the model as main effects. The *splines* package also has several functions to create nonlinear spline terms in the formula.

* For data sets where there are many predictors, the period shortcut is available.The period represents the main effects for all of the columns that are not on the left-hand side of the tilde. Using `~(.)^3` would create main effects as well as all two-and three-variable interactions to the model.

Returning to our chirping crickets, let's use a two-way interaction model. In this book, we use the suffix `_fit` for R objects that are fitted models.

```{r Our first look at interaction fits}

interaction_fit <- lm(rate ~ (temp + species) ^2, data = crickets)

```

Let's look at a short summary of the model:

```{r Summary of the model}

interaction_fit

```

The output is a little hard to read. For the species indicator variables, R measures the variable name (parenthesis parenthesis (`species`)together with a factor level (`O.Niveus`) with no delimiter.

Before going into any inferential results for this model, the fit should be assessed using diagnostic plots. We can use the `plot()` method for `lm` objects this method produces a set of four plots for the object each showing different aspects of the fit, as shown in figure 3.2.

```{r Plot our results. Start with two plots next to each other}

par(mfrow = c(1,2))

plot(interaction_fit, which = 1) # residual vs filled

plot(interaction_fit, which = 2) # Normal Q-Q plot

```

Our next order of business with the crickets is to assess if the inclusion of the interaction term is necessary. The most appropriate approach for this model is to recompute the model without the interaction term and use the `anova()` method.

```{r Recalculate the model without the interaction terms}

# Fit a reduced model:

main_effect_fit <- lm(rate ~ temp + species, data = crickets)

```

Now compare the two using ANOVA:

```{r Compare with and without interaction using ANOVA}

anova(main_effect_fit, interaction_fit)

```

The statistical test generates a p-value of 0.25. This implies that there is a lack of sufficient evidence against the hull hypothesis that the interaction term is not needed by the model. For this reason, we will conduct further analysis on the model without the interaction.

Residual plots should be re-assessed to make sure that our theoretical assumptions are valid enough to trust the p-values produced by the model.

```{r Check residuals of the model}

plot(main_effect_fit, which = 1)

```

We can use the command `summary()`to inspect the coefficients, standard errors, and p-values of each model term:

```{r Summary of main_effect_fit}

summary(main_effect_fit)

```

The chirp rate for each species increases by 3.6 chirps as the temperature increases by a single degree. This term shows strong statistical significance as evidenced by the p-value. The species term has a value of -10.07. This indicates that, across all temperature values, *O. niveus* rate that is about 10 fewer chips per minute then *O. exclamationis*. Similar to the temperature term, the species affect is associated with a very small p-value.

The only issue in this analysis is the intercept value. It indicates at 0° C, there are negative chirps per minute for both species. While this doesn't make sense, the data only go as far as 17.2° C. Interpreting the model at 0° C would be an extrapolation. This would be a bad idea. That being said, the model is a good fit within the applicable range of the temperature values: the conclusions should be limited to the observed temperature range.

If we needed to estimate the chirp rate at a temperature that was not observed in the experiment, we could use the `predict` method. It takes the model object and a data frame of new values for prediction For example, the model estimates the chirp rate for a period four temperatures between 15° C and 20° C can be computed via:

```{r Predicting chirp rate between 15º C and 20º C}

new_values <- data.frame(species = "O. exclamationis", temp = 15:20)
predict(main_effect_fit, new_values)

```

While this analysis has obviously not been an exhaustive demonstration of ours modeling capabilities, it does highlight some major features important for the rest of the book

*the language has an expressive syntax for specifying model terms for both simple and quite complex models.

*The R formula method has many conveniences for modeling that are also applied to new data when predictions are generated.

*There are numerous helper functions(e.g. `anova()`, `summary()`, and `predict()`) that you can use to conduct specific calculations after the fitted model is created.

Finally, it's previously mentioned, this framework was first published in 1992. Most of these ideas and methods were developed in that. But ever made remarkably relevant to this day. It highlights that the S language eight, by extension R, has been designed for data analysis since it's inception.

## 3.2 What does the R formula do?

The R model formula is used by many modeling packages. It usually serves multiple purposes.

* The formula defines the columns that the model uses.
* The standard R machinery uses the formula to encoe the columns into an appropirate format.
* The foles of the columns are defined by the formula.

Our focus, when seeing this, is that there are two projectors in the model shown contain their main effects and their two-weight interactions. However, this formula also implies that, since ` ` is a factor, it should also create indicator variable columns for this predictor. It should also multiply those columns by the ` ` column to create the interactions. This transformation represents our second bullet point on encoding; the formula also define how each column is encoded and can create additional columns that are not in the original data.

## 3.3 Why tidinss is important for modeling

The tiny models package have a set of design goals. Most of the tidy models design goals fall under the existing rubric of The tidy models design goals fall under the existing rubric of "design for humans "from the tidy verse, but with specific applications from modeling code. There are a few additional tidy models design goals the complement those of the tidy verse. Some examples:

*R has excellent capabilities for object oriented programming, and we use this in Lou of creating new function names (such as the hypothetical new ` `).
**Sensible to faults*covered important. Also, functions should have no default for arguments when it is more appropriate for the user to make a choice (E. GPR, the file name argument for back t
*Similarly, argument values was the fault can be derived from the data should be. For example, 4 ` ` the ` ` argument could check the type of data in the outcome and, if not ` ` was given a default could be determined internally.
*Functions to take the*data structures*that users have as opposed to the data structure that developers want. For example a model functions only interface should not be constrained to matrices. Frequently users will have nonnumeric protectors, such as factors.

Many of these ideas are described in the tidymodels guideline for model implementation. In subsequent chapters, we will illustrate examples of existing issues, along with their solutions.

The `broom::tidy()` function, which we use through this book, is another tool for standardizing the structure of R objects. It can return many types of R objects in a more usable format. For example, suppose that predictors are being screened based on their correlation to the outcome columns. Using `purrr::map()`, the results from `cor.test()` can be returned in a list for each predictor:

```{r Screening predictors based on their correlation to the outcome column}

corr_res <- map(mtcars %>% select(-mpg), cor.test, y = mtcars$mpg)

# The first of ten results in the vector:

corr_res[[1]]
```

Interpretation: There is a 95 percent chance that the null hypothesis - that the correlation is equal to zero - is not supported by the data, and we have enough data to reject the null hypothesis. Based on the data, the most likely correlation is -0.852162.

If we want to use the results in a plot, the standard format of hypothesis test results are not very useful. The `tidy()` method can return this as a tibble with standardized names:

```{r tidyverse return the correlation with standardized names}

tidy(corr_res[[1]])

```

These results can be "stacked" and added to a `ggplot()` as shown in figure 3.3:

```{r "Stacking" results}

corr_res %>% 
  # convert to a tidy format; `map_dfr()` stacks the data frames:
  
  map_dfr(tidy, .id = "predictor") %>% 
  ggplot(aes(x = fct_reorder(predictor, estimate))) +
  geom_point(aes(y = estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high, width = 0.1)) +
  labs(x = NULL, y = "Correlation with mpg") +
  ggtitle("Figure 3.3:Correlations and 95% confidence intervals between predictors and the outcome in the `mtcars` data set")

```

## Combining Base R Models and the Tidyverse

R modeling functions from the core language or other R packages can be used in conjunction with the tidyverse, especially with the **dplyr, purr**, and **tidyr** packages. For example, if we wanted to fit separate models for each cricket species, we can first break out the cricket data by this column (species) using `dplor::group_nest()`

```{r Break out each group by species}

split_by_species <- 
  crickets %>% 
  group_nest(species)
split_by_species

```

The `data` cp;i,m contains the `rate` and `temp` columns from `crickets` in a *list column*. From this, the `purr::map()` function can create individual models for each species:

```{r Create individual models for each species}

model_by_species <- 
  split_by_species %>% 
  mutate(model = map(data, ~ lm(rate ~ temp, data = .x)))
model_by_species

```

To collect the coefficients for each of these models, we use `broom::tidy()` to convert them to a consisten data frame format so that they can be unnested:

```{r Convert to a consistent format and unnest the data}

model_by_species %>% 
  mutate(coef = map(model, tidy)) %>% 
  select(species, coef) %>% 
  unnest(cols = c(coef))

```

